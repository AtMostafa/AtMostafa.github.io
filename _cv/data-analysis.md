---
title: "Data Analysis"
date: 2020-09-10
featured: true
weight: 19
---

Looking into a large and complex set of data to draw statistical inferences.

I've spent a lot of time playing with data. It might not qualify as data science in that I haven't used machine/deep learning, rather I've coded pipelines to regroup, label and visualise raw data.
Proper visualisation of a noisy and complex database goes a long way in revealing hidden patterns or anomalies.

My favourite language used to be _Matlab_, but to do my PhD, I learnt _Python_ and now I do not want to go back!
Below, I elaborate how I do things and my toys of choice.


# Python _3.x_
Personal experience of moving to Python from Matlab belongs to another place _[coming soon]_.

# Anaconda environments
In every computer, [Anaconda](https://www.anaconda.com/products/individual) is one of the first things I install.
I use a separate [environment](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) for each project to meet the dependencies and avoid conflicts, which happen in the python ecosystem and are devastating.

# Jupyter notebooks
[Notebooks](https://jupyter.org/) are awesome for tinkering, which is most what one does when performing new analyses or developing new tools.
I mostly used [Jupyter Lab](https://jupyterlab.readthedocs.io/en/stable/) to work with notebooks.
However, recently Visual Studio Code is improving its support of notebooks, it might be worth trying it out!

# Publication-ready plotting


[...]